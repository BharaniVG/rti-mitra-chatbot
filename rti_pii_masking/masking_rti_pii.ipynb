{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9af2a-e2a8-473f-9326-b328287f3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a `.env` file (for API keys, URLs)\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configurable Constants ---\n",
    "ANYTHINGLLM_API_URL = \"http://localhost:3001/api/v1/openai/chat/completions\"\n",
    "ANYTHINGLLM_MODEL = \"removepiidata_openaioss\"  # Workspace name in AnythingLLM\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL = \"llama3.2\"  # Update if you use a different locally pulled model\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def clean_llm_response(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove common LLM-generated prefixes such as 'Here is the redacted text:'.\n",
    "    \"\"\"\n",
    "    unwanted_prefixes = [\n",
    "        \"Here is the redacted text:\",\n",
    "        \"The redacted version is:\",\n",
    "        \"Masked version:\",\n",
    "        \"Anonymized output:\",\n",
    "        \"Output:\",\n",
    "    ]\n",
    "    for prefix in unwanted_prefixes:\n",
    "        if response.strip().lower().startswith(prefix.lower()):\n",
    "            return response[len(prefix):].strip()\n",
    "    return response.strip()\n",
    "\n",
    "def mask_pii_using_ollama(text):\n",
    "    \"\"\"\n",
    "    Use a locally running Ollama LLM to mask PII from the given RTI text.\n",
    "    Returns redacted text.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return text\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Mask all PII in the text below. Do not rewrite, explain, or generate anything extra. Just replace PII with tags.\n",
    "\n",
    "The following text is part of a user-submitted Right to Information (RTI) request. It may contain personal details, dates, names, addresses, ID numbers, or sensitive information.\n",
    "\n",
    "Your job is to only mask personally identifiable information (PII) by replacing:\n",
    "- Names ‚Üí [MASKED_NAME]\n",
    "- Addresses ‚Üí [MASKED_ADDRESS]\n",
    "- Phone Numbers ‚Üí [MASKED_PHONE_NUMBER]\n",
    "- Company Names ‚Üí [MASKED_COMPANY_NAME]\n",
    "- Dates ‚Üí [MASKED_DATE]\n",
    "- Any IDs (PAN, Aadhar, Bill Numbers, EPF, etc.) ‚Üí [MASKED_ID]\n",
    "\n",
    "Preserve all section markers like <<TITLE>>, <<USER DESCRIPTION>>, etc.\n",
    "Do not rewrite or rephrase. Do not include headers or explanations.\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_URL, json={\n",
    "            \"model\": MODEL,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        })\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            raw_output = response.json().get(\"response\", \"\")\n",
    "            return clean_llm_response(raw_output)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error contacting Ollama: {e}\")\n",
    "        return text\n",
    "\n",
    "def mask_pii_using_anythingllm(text):\n",
    "    \"\"\"\n",
    "    Use AnythingLLM's API to redact PII from the given text using a workspace.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        print(\"Error: Empty or invalid input.\")\n",
    "        return text\n",
    "\n",
    "    api_key = os.getenv(\"ANYTHINGLLM_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"‚ùå Missing API key. Set ANYTHINGLLM_API_KEY in your environment or .env file.\")\n",
    "        return text\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            ANYTHINGLLM_API_URL,\n",
    "            headers={\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {api_key}\"\n",
    "            },\n",
    "            json={\n",
    "                \"model\": ANYTHINGLLM_MODEL,\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": text\n",
    "                    }\n",
    "                ],\n",
    "                \"stream\": False\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        else:\n",
    "            print(f\"‚ùå API Error {response.status_code}: {response.text}\")\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error contacting AnythingLLM: {e}\")\n",
    "        return text\n",
    "\n",
    "# --- Core Batch Processing Function ---\n",
    "\n",
    "def mask_pii_rti(input_path, intermediate_csv_path, final_xlsx_path,\n",
    "                 columns_to_mask, columns_to_save_withoutmasking=[], batch_size=100, delete_csv_after=True):\n",
    "    \"\"\"\n",
    "    Process RTI rows in batches. Mask PII using AnythingLLM.\n",
    "    Save intermediate results to CSV (safe for crash recovery).\n",
    "    At the end, convert the CSV to one final Excel file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load input Excel\n",
    "    try:\n",
    "        df = pd.read_excel(input_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading Excel file: {e}\")\n",
    "        return\n",
    "\n",
    "    total_rows = len(df)\n",
    "    total_batches = math.ceil(total_rows / batch_size)\n",
    "    print(f\"üìÑ Total RTIs to process: {total_rows} (Batch size: {batch_size}, Total batches: {total_batches})\")\n",
    "\n",
    "    overall_start = time.time()\n",
    "\n",
    "    # Clean existing CSV if present\n",
    "    if os.path.exists(intermediate_csv_path):\n",
    "        os.remove(intermediate_csv_path)\n",
    "\n",
    "    # Process in batches\n",
    "    for batch_num in range(total_batches):\n",
    "        batch_start_index = batch_num * batch_size\n",
    "        batch_end_index = min((batch_num + 1) * batch_size, total_rows)\n",
    "        batch_df = df.iloc[batch_start_index:batch_end_index].copy()\n",
    "\n",
    "        print(f\"\\nüöÄ Processing batch {batch_num + 1} ({batch_start_index + 1} to {batch_end_index})\")\n",
    "\n",
    "        batch_output_rows = []\n",
    "\n",
    "        for index in batch_df.index:\n",
    "            row_start = time.time()\n",
    "            rti_number = df.at[index, \"Number\"] if \"Number\" in df.columns else f\"Row {index}\"\n",
    "            print(f\"üîç Processing RTI: {rti_number}\")\n",
    "\n",
    "            # Combine fields with markers\n",
    "            combined_text = \"\\n\\n\".join([\n",
    "                f\"<<{col.upper()}>>\\n{str(df.at[index, col])}\"\n",
    "                for col in columns_to_mask if col in df.columns and pd.notna(df.at[index, col])\n",
    "            ])\n",
    "\n",
    "            masked_output = mask_pii_using_anythingllm(combined_text)\n",
    "\n",
    "            # Parse masked text back into fields\n",
    "            output_row = {col: df.at[index, col] for col in columns_to_save_withoutmasking}\n",
    "            for col in columns_to_mask:\n",
    "                tag = f\"<<{col.upper()}>>\"\n",
    "                pattern = re.compile(rf\"{re.escape(tag)}\\s*(.*?)(?=(?:<<[A-Z _]+>>)|\\Z)\", re.DOTALL)\n",
    "                match = pattern.search(masked_output)\n",
    "                output_row[f\"Masked {col}\"] = match.group(1).strip() if match else \"\"\n",
    "\n",
    "            batch_output_rows.append(output_row)\n",
    "            print(f\"‚úÖ Done with RTI {rti_number} | ‚è±Ô∏è Time taken: {round(time.time() - row_start, 2)} sec\")\n",
    "\n",
    "        # Save batch to intermediate CSV\n",
    "        try:\n",
    "            batch_output_df = pd.DataFrame(batch_output_rows)\n",
    "            write_header = not os.path.exists(intermediate_csv_path)\n",
    "            batch_output_df.to_csv(intermediate_csv_path, mode='a', index=False, header=write_header, encoding='utf-8')\n",
    "            print(f\"üíæ Appended batch {batch_num + 1} to: {intermediate_csv_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving batch {batch_num + 1} to CSV: {e}\")\n",
    "\n",
    "    # Convert CSV to Excel\n",
    "    try:\n",
    "        final_df = pd.read_csv(intermediate_csv_path)\n",
    "        final_dir = os.path.dirname(final_xlsx_path)\n",
    "        if final_dir:\n",
    "            os.makedirs(final_dir, exist_ok=True)\n",
    "        final_df.to_excel(final_xlsx_path, index=False)\n",
    "        print(f\"\\n‚úÖ Final Excel file saved to: {final_xlsx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error converting CSV to Excel: {e}\")\n",
    "\n",
    "    # Optional cleanup\n",
    "    if delete_csv_after:\n",
    "        try:\n",
    "            os.remove(intermediate_csv_path)\n",
    "            print(f\"üßπ Deleted intermediate CSV: {intermediate_csv_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not delete intermediate CSV: {e}\")\n",
    "\n",
    "    total_time = time.time() - overall_start\n",
    "    print(f\"\\n‚è±Ô∏è Total processing time: {round(total_time, 2)} sec\")\n",
    "    print(f\"üïí Avg per RTI: {round(total_time / total_rows, 2)} sec\")\n",
    "\n",
    "# --- Optional Column-wise Redaction Function ---\n",
    "\n",
    "def redact_excel_file(input_path, output_path, pii_columns):\n",
    "    \"\"\"\n",
    "    Redacts each specified column individually using Ollama (for testing).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(input_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        return\n",
    "\n",
    "    for col in pii_columns:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Column '{col}' not found in Excel. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Masking PII in column: {col}\")\n",
    "        df[col] = df[col].apply(mask_pii_using_ollama)\n",
    "\n",
    "    try:\n",
    "        df.to_excel(output_path, index=False)\n",
    "        print(f\"‚úÖ Anonymized Excel saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving redacted Excel file: {e}\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    input_file = \"./test.xlsx\"\n",
    "    output_file = \"./test_outputOpenAI.xlsx\"\n",
    "    temp_file = \"./mask_pii_rti.csv\"\n",
    "\n",
    "    # Columns to process\n",
    "    columns_to_mask_pii = [\"Title\", \"User Description\", \"Drafter Modified Title\", \"Drafter Modified Description\"]\n",
    "    columns_to_save_withoutmasking = [\"Number\"]\n",
    "\n",
    "    # Run PII masking\n",
    "    mask_pii_rti(\n",
    "        input_file,\n",
    "        temp_file,\n",
    "        output_file,\n",
    "        columns_to_mask_pii,\n",
    "        columns_to_save_withoutmasking,\n",
    "        BATCH_SIZE,\n",
    "        delete_csv_after=True\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12413d-d5d8-4f20-b054-4d888d5167a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebdc06d-8016-439a-9843-c1b8f6dc7e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
